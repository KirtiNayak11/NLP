{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 5094410,
          "sourceType": "datasetVersion",
          "datasetId": 2958426
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KirtiNayak11/NLP/blob/main/fine_tune_t5_for_conversational_model_using_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:10.242070Z",
          "iopub.execute_input": "2025-03-04T17:43:10.242406Z",
          "iopub.status.idle": "2025-03-04T17:43:11.356645Z",
          "shell.execute_reply.started": "2025-03-04T17:43:10.242369Z",
          "shell.execute_reply": "2025-03-04T17:43:11.355322Z"
        },
        "id": "BV0c11y1MiAw",
        "outputId": "72f39048-e588-4c3f-a755-acf7b94a795d"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/3k-conversations-dataset-for-chatbot/Conversation.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:11.357711Z",
          "iopub.execute_input": "2025-03-04T17:43:11.358230Z",
          "iopub.status.idle": "2025-03-04T17:43:28.018310Z",
          "shell.execute_reply.started": "2025-03-04T17:43:11.358199Z",
          "shell.execute_reply": "2025-03-04T17:43:28.017100Z"
        },
        "id": "FF04VC8wMiA4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/kaggle/input/3k-conversations-dataset-for-chatbot/Conversation.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.020457Z",
          "iopub.execute_input": "2025-03-04T17:43:28.021102Z",
          "iopub.status.idle": "2025-03-04T17:43:28.061215Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.021070Z",
          "shell.execute_reply": "2025-03-04T17:43:28.060241Z"
        },
        "id": "EV7n8aaUMiA5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.062502Z",
          "iopub.execute_input": "2025-03-04T17:43:28.062781Z",
          "iopub.status.idle": "2025-03-04T17:43:28.088392Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.062758Z",
          "shell.execute_reply": "2025-03-04T17:43:28.087225Z"
        },
        "id": "Jwrm7A8bMiA5",
        "outputId": "b405e7be-e766-4940-86a9-c6d166d26424"
      },
      "outputs": [
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0                             question  \\\n0           0               hi, how are you doing?   \n1           1        i'm fine. how about yourself?   \n2           2  i'm pretty good. thanks for asking.   \n3           3    no problem. so how have you been?   \n4           4     i've been great. what about you?   \n\n                                     answer  \n0             i'm fine. how about yourself?  \n1       i'm pretty good. thanks for asking.  \n2         no problem. so how have you been?  \n3          i've been great. what about you?  \n4  i've been good. i'm in school right now.  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>hi, how are you doing?</td>\n      <td>i'm fine. how about yourself?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>i'm fine. how about yourself?</td>\n      <td>i'm pretty good. thanks for asking.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>i'm pretty good. thanks for asking.</td>\n      <td>no problem. so how have you been?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>no problem. so how have you been?</td>\n      <td>i've been great. what about you?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>i've been great. what about you?</td>\n      <td>i've been good. i'm in school right now.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.089589Z",
          "iopub.execute_input": "2025-03-04T17:43:28.089995Z",
          "iopub.status.idle": "2025-03-04T17:43:28.098115Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.089962Z",
          "shell.execute_reply": "2025-03-04T17:43:28.097074Z"
        },
        "id": "0mAliVAQMiA7",
        "outputId": "679ebfa2-fdb4-495b-df8a-654341175679"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(3725, 3)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.098930Z",
          "iopub.execute_input": "2025-03-04T17:43:28.099194Z",
          "iopub.status.idle": "2025-03-04T17:43:28.119879Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.099172Z",
          "shell.execute_reply": "2025-03-04T17:43:28.118558Z"
        },
        "id": "kQnxbjFiMiA7",
        "outputId": "1d6d9f9d-59a0-486a-fe84-97e07fc237cb"
      },
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['Unnamed: 0', 'question', 'answer'], dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(columns = ['Unnamed: 0'],inplace = True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.120787Z",
          "iopub.execute_input": "2025-03-04T17:43:28.121295Z",
          "iopub.status.idle": "2025-03-04T17:43:28.146505Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.121259Z",
          "shell.execute_reply": "2025-03-04T17:43:28.145328Z"
        },
        "id": "jpodXZgjMiA8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.150824Z",
          "iopub.execute_input": "2025-03-04T17:43:28.151290Z",
          "iopub.status.idle": "2025-03-04T17:43:28.172271Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.151244Z",
          "shell.execute_reply": "2025-03-04T17:43:28.171009Z"
        },
        "id": "qN8TmNkuMiA-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df.duplicated()])\n",
        "print(df.duplicated().sum())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.174211Z",
          "iopub.execute_input": "2025-03-04T17:43:28.174523Z",
          "iopub.status.idle": "2025-03-04T17:43:28.206080Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.174495Z",
          "shell.execute_reply": "2025-03-04T17:43:28.204806Z"
        },
        "id": "wGOM5zI8MiA_",
        "outputId": "760be3a8-41ee-459e-db0c-681dedc73e0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "                          question    answer\n1749  i don't like riding the bus.  why not?\n1\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop_duplicates(inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.207086Z",
          "iopub.execute_input": "2025-03-04T17:43:28.207496Z",
          "iopub.status.idle": "2025-03-04T17:43:28.214801Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.207458Z",
          "shell.execute_reply": "2025-03-04T17:43:28.213746Z"
        },
        "id": "bo2OGahJMiA_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.215846Z",
          "iopub.execute_input": "2025-03-04T17:43:28.216249Z",
          "iopub.status.idle": "2025-03-04T17:43:28.236572Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.216222Z",
          "shell.execute_reply": "2025-03-04T17:43:28.235484Z"
        },
        "id": "EiaB0hYwMiBA",
        "outputId": "1f3d6035-e960-405b-add2-5b24f6474327"
      },
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.237734Z",
          "iopub.execute_input": "2025-03-04T17:43:28.238061Z",
          "iopub.status.idle": "2025-03-04T17:43:28.255458Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.238027Z",
          "shell.execute_reply": "2025-03-04T17:43:28.254454Z"
        },
        "id": "Y3pttrLlMiBB",
        "outputId": "c9f6fd90-d707-429c-f233-4e31f6b82ff5"
      },
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "question    0\nanswer      0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.256318Z",
          "iopub.execute_input": "2025-03-04T17:43:28.256675Z",
          "iopub.status.idle": "2025-03-04T17:43:28.275087Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.256649Z",
          "shell.execute_reply": "2025-03-04T17:43:28.274038Z"
        },
        "id": "17k7EFxHMiBB",
        "outputId": "3b881135-ae62-436c-d489-f0d696130f1a"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(3724, 2)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n",
        "\n",
        "1.Lowercase all characters\n",
        "\n",
        "2.Remove quotes\n",
        "\n",
        "3.Remove all the special characters\n",
        "\n",
        "4.Remove all numbers from text\n",
        "\n",
        "5.Remove extra spaces\n"
      ],
      "metadata": {
        "id": "U1XJWrfOMiBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.275958Z",
          "iopub.execute_input": "2025-03-04T17:43:28.276309Z",
          "iopub.status.idle": "2025-03-04T17:43:28.295405Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.276283Z",
          "shell.execute_reply": "2025-03-04T17:43:28.294260Z"
        },
        "id": "A-Lj17hMMiBF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(\"'\",'',text)\n",
        "    text = re.sub(r'[^a-z\\s]','',text)\n",
        "    text = re.sub(r'\\s+',' ',text).strip()\n",
        "    return text\n",
        "\n",
        "df = df.map(preprocess_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.296698Z",
          "iopub.execute_input": "2025-03-04T17:43:28.297086Z",
          "iopub.status.idle": "2025-03-04T17:43:28.362943Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.297053Z",
          "shell.execute_reply": "2025-03-04T17:43:28.361832Z"
        },
        "id": "hdf0_T7aMiBF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['answer'] = df['answer'].apply(lambda x:'START_' + x + '_END')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.363966Z",
          "iopub.execute_input": "2025-03-04T17:43:28.364268Z",
          "iopub.status.idle": "2025-03-04T17:43:28.371693Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.364243Z",
          "shell.execute_reply": "2025-03-04T17:43:28.370564Z"
        },
        "id": "mjGMaoNSMiBF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.372747Z",
          "iopub.execute_input": "2025-03-04T17:43:28.373074Z",
          "iopub.status.idle": "2025-03-04T17:43:28.396628Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.373047Z",
          "shell.execute_reply": "2025-03-04T17:43:28.395564Z"
        },
        "id": "ozM_8pixMiBF",
        "outputId": "0948656f-8867-4838-ea42-30a761ada85f"
      },
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                           question  \\\n0              hi how are you doing   \n1        im fine how about yourself   \n2  im pretty good thanks for asking   \n3   no problem so how have you been   \n4     ive been great what about you   \n\n                                           answer  \n0            START_im fine how about yourself_END  \n1      START_im pretty good thanks for asking_END  \n2       START_no problem so how have you been_END  \n3         START_ive been great what about you_END  \n4  START_ive been good im in school right now_END  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi how are you doing</td>\n      <td>START_im fine how about yourself_END</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>im fine how about yourself</td>\n      <td>START_im pretty good thanks for asking_END</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>im pretty good thanks for asking</td>\n      <td>START_no problem so how have you been_END</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>no problem so how have you been</td>\n      <td>START_ive been great what about you_END</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ive been great what about you</td>\n      <td>START_ive been good im in school right now_END</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.397635Z",
          "iopub.execute_input": "2025-03-04T17:43:28.398056Z",
          "iopub.status.idle": "2025-03-04T17:43:28.413814Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.398015Z",
          "shell.execute_reply": "2025-03-04T17:43:28.412985Z"
        },
        "id": "UPkFiSKUMiBH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    tokenizer.fit_on_texts(text)\n",
        "    total_words = (tokenizer.word_index)\n",
        "    tensor = tokenizer.texts_to_sequences(text)[0]\n",
        "    max_seq_len = max([len(x) for x in tensor])\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\\\n",
        "                                                           padding = 'post',\\\n",
        "                                                           maxlen = max_seq_len,\\\n",
        "                                                           dtype='int32')\n",
        "\n",
        "    return total_words,tensor,tokenizer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.415020Z",
          "iopub.execute_input": "2025-03-04T17:43:28.415401Z",
          "iopub.status.idle": "2025-03-04T17:43:28.435752Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.415373Z",
          "shell.execute_reply": "2025-03-04T17:43:28.434649Z"
        },
        "id": "WFyRboMSMiBH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "total_input_words,input_sequence,input_tokenizer = tokenize(df['question'].tolist())\n",
        "total_output_words,output_sequence,output_tokenizer = tokenize(df['answer'].tolist())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.437081Z",
          "iopub.execute_input": "2025-03-04T17:43:28.437497Z",
          "iopub.status.idle": "2025-03-04T17:43:28.580509Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.437459Z",
          "shell.execute_reply": "2025-03-04T17:43:28.579367Z"
        },
        "id": "nxfdwJs3MiBI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "input_vocab_size = len(total_input_words) + 1\n",
        "output_vocab_size = len(total_output_words) + 1\n",
        "max_input_length = input_sequence.shape[1]\n",
        "max_output_length = output_sequence.shape[1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.581836Z",
          "iopub.execute_input": "2025-03-04T17:43:28.582186Z",
          "iopub.status.idle": "2025-03-04T17:43:28.586993Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.582156Z",
          "shell.execute_reply": "2025-03-04T17:43:28.585831Z"
        },
        "id": "AccjkYXZMiBI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_units = 256"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.588089Z",
          "iopub.execute_input": "2025-03-04T17:43:28.588506Z",
          "iopub.status.idle": "2025-03-04T17:43:28.608415Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.588465Z",
          "shell.execute_reply": "2025-03-04T17:43:28.607256Z"
        },
        "id": "L3kUmNj7MiBI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.612828Z",
          "iopub.execute_input": "2025-03-04T17:43:28.613260Z",
          "iopub.status.idle": "2025-03-04T17:43:28.630667Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.613225Z",
          "shell.execute_reply": "2025-03-04T17:43:28.629435Z"
        },
        "id": "EcBqioS1MiBJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = Input(shape = (max_input_length,))\n",
        "encoder_embedding_layer = Embedding(input_dim = input_vocab_size,output_dim = 100,mask_zero = True)(encoder_inputs)\n",
        "encoder = LSTM(lstm_units,return_state=True)\n",
        "encoder_outputs,state_h,state_c = encoder(encoder_embedding_layer)\n",
        "encoder_states = [state_h,state_c]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.632435Z",
          "iopub.execute_input": "2025-03-04T17:43:28.632850Z",
          "iopub.status.idle": "2025-03-04T17:43:28.790437Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.632805Z",
          "shell.execute_reply": "2025-03-04T17:43:28.789457Z"
        },
        "id": "JTZfqL6yMiBJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_units=256\n",
        "\n",
        "encoder_inputs = Input(shape = (input_sequence.shape[1],))\n",
        "embedding_layer = Embedding(input_dim = len(total_input_words)+1,output_dim = 100,mask_zero = True)(encoder_inputs)\n",
        "encoder = LSTM(lstm_units,return_state=True)\n",
        "encoder_outputs,state_h,state_c = encoder(embedding_layer)\n",
        "encoder_states = [state_h,state_c]\n",
        "\n",
        "encoder_model = Model(encoder_inputs,encoder_states)\n",
        "\n",
        "decoder_inputs = Input(shape = (max_output_length,))\n",
        "decoder_embedding_layer = Embedding(input_dim = output_vocab_size,output_dim = 100,mask_zero = True)(decoder_inputs)\n",
        "\n",
        "decoder = LSTM(lstm_units,return_sequences = True,return_state = True)\n",
        "decoder_outputs,state_h,state_c = decoder(decoder_embedding_layer,initial_state=encoder_states)\n",
        "\n",
        "decoder_dense = Dense(output_vocab_size,activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.791459Z",
          "iopub.execute_input": "2025-03-04T17:43:28.791826Z",
          "iopub.status.idle": "2025-03-04T17:43:28.934376Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.791793Z",
          "shell.execute_reply": "2025-03-04T17:43:28.933287Z"
        },
        "id": "ofInXpcHMiBJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.935469Z",
          "iopub.execute_input": "2025-03-04T17:43:28.935854Z",
          "iopub.status.idle": "2025-03-04T17:43:28.943671Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.935817Z",
          "shell.execute_reply": "2025-03-04T17:43:28.942346Z"
        },
        "id": "nwJS6K5GMiBK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print summary\n",
        "model.summary()\n",
        "\n",
        "# ---- TRAINING ----\n",
        "# Convert decoder output to one-hot encoding\n",
        "decoder_target_data = tf.keras.utils.to_categorical(output_sequence, num_classes=output_vocab_size)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:43:28.944939Z",
          "iopub.execute_input": "2025-03-04T17:43:28.945367Z",
          "iopub.status.idle": "2025-03-04T17:43:29.256149Z",
          "shell.execute_reply.started": "2025-03-04T17:43:28.945326Z",
          "shell.execute_reply": "2025-03-04T17:43:29.255088Z"
        },
        "id": "Ipq5GrLwMiBK",
        "outputId": "28aa2ad0-0b3b-430c-fbce-43c0484e1fdb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1mModel: \"functional_1\"\u001b[0m\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m233,800\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_1 (\u001b[38;5;33mNotEqual\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m100\u001b[0m)        │        \u001b[38;5;34m349,000\u001b[0m │ input_layer_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,   │        \u001b[38;5;34m365,568\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │ \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)]     │                │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m),      │        \u001b[38;5;34m365,568\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n│                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m), (\u001b[38;5;45mNone\u001b[0m,    │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m1\u001b[0m],          │\n│                           │ \u001b[38;5;34m256\u001b[0m)]                  │                │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m2\u001b[0m]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3490\u001b[0m)       │        \u001b[38;5;34m896,930\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ input_layer_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">233,800</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ not_equal_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">349,000</span> │ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]     │                │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">365,568</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n│                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>), (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,    │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>],          │\n│                           │ <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)]                  │                │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3490</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896,930</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,210,866\u001b[0m (8.43 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,210,866</span> (8.43 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,210,866\u001b[0m (8.43 MB)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,210,866</span> (8.43 MB)\n</pre>\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n",
            "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "checkpoint_path = \"/kaggle/working/model_checkpoint.keras\"  # Change to .keras\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=False,  # Save full model\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:48:25.639779Z",
          "iopub.execute_input": "2025-03-04T17:48:25.640258Z",
          "iopub.status.idle": "2025-03-04T17:48:25.645943Z",
          "shell.execute_reply.started": "2025-03-04T17:48:25.640223Z",
          "shell.execute_reply": "2025-03-04T17:48:25.644583Z"
        },
        "id": "6Eyn6ViBMiBK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit([input_sequence, output_sequence], decoder_target_data,\n",
        "          batch_size=64, epochs=50, validation_split=0.2,callbacks=[cp_callback]\n",
        "         )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-04T17:48:25.647765Z",
          "iopub.execute_input": "2025-03-04T17:48:25.648243Z"
        },
        "id": "ff8hj5JnMiBL",
        "outputId": "9a9bfd52-8a56-4d9b-cc1d-b3312b9bd3f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step - accuracy: 0.0138 - loss: 8.0295\nEpoch 1: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 450ms/step - accuracy: 0.0138 - loss: 8.0218 - val_accuracy: 0.0185 - val_loss: 6.8338\nEpoch 2/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.0182 - loss: 6.5264\nEpoch 2: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 418ms/step - accuracy: 0.0182 - loss: 6.5247 - val_accuracy: 0.0205 - val_loss: 6.5610\nEpoch 3/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397ms/step - accuracy: 0.0214 - loss: 6.2542\nEpoch 3: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 430ms/step - accuracy: 0.0214 - loss: 6.2535 - val_accuracy: 0.0195 - val_loss: 6.4831\nEpoch 4/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.0214 - loss: 6.1228\nEpoch 4: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 426ms/step - accuracy: 0.0214 - loss: 6.1227 - val_accuracy: 0.0207 - val_loss: 6.4195\nEpoch 5/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.0225 - loss: 6.0352\nEpoch 5: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 413ms/step - accuracy: 0.0225 - loss: 6.0350 - val_accuracy: 0.0206 - val_loss: 6.3376\nEpoch 6/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.0232 - loss: 5.8720\nEpoch 6: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 421ms/step - accuracy: 0.0232 - loss: 5.8717 - val_accuracy: 0.0230 - val_loss: 6.1462\nEpoch 7/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.0284 - loss: 5.6858\nEpoch 7: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 409ms/step - accuracy: 0.0285 - loss: 5.6852 - val_accuracy: 0.0289 - val_loss: 6.0053\nEpoch 8/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.0352 - loss: 5.5114\nEpoch 8: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 424ms/step - accuracy: 0.0353 - loss: 5.5116 - val_accuracy: 0.0425 - val_loss: 5.8894\nEpoch 9/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391ms/step - accuracy: 0.0470 - loss: 5.4048\nEpoch 9: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 421ms/step - accuracy: 0.0471 - loss: 5.4043 - val_accuracy: 0.0541 - val_loss: 5.7615\nEpoch 10/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.0557 - loss: 5.2233\nEpoch 10: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 412ms/step - accuracy: 0.0557 - loss: 5.2234 - val_accuracy: 0.0566 - val_loss: 5.6218\nEpoch 11/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.0625 - loss: 5.0795\nEpoch 11: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 424ms/step - accuracy: 0.0625 - loss: 5.0795 - val_accuracy: 0.0668 - val_loss: 5.5031\nEpoch 12/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.0694 - loss: 4.9609\nEpoch 12: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 415ms/step - accuracy: 0.0695 - loss: 4.9607 - val_accuracy: 0.0687 - val_loss: 5.3911\nEpoch 13/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.0738 - loss: 4.8466\nEpoch 13: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 424ms/step - accuracy: 0.0738 - loss: 4.8460 - val_accuracy: 0.0783 - val_loss: 5.2882\nEpoch 14/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411ms/step - accuracy: 0.0817 - loss: 4.6731\nEpoch 14: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 443ms/step - accuracy: 0.0817 - loss: 4.6734 - val_accuracy: 0.0812 - val_loss: 5.1739\nEpoch 15/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394ms/step - accuracy: 0.0883 - loss: 4.5593\nEpoch 15: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 425ms/step - accuracy: 0.0883 - loss: 4.5591 - val_accuracy: 0.0892 - val_loss: 5.0549\nEpoch 16/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400ms/step - accuracy: 0.0941 - loss: 4.3988\nEpoch 16: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 431ms/step - accuracy: 0.0942 - loss: 4.3989 - val_accuracy: 0.0986 - val_loss: 4.9168\nEpoch 17/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.1061 - loss: 4.2436\nEpoch 17: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 448ms/step - accuracy: 0.1060 - loss: 4.2439 - val_accuracy: 0.1084 - val_loss: 4.7946\nEpoch 18/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.1118 - loss: 4.1199\nEpoch 18: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 442ms/step - accuracy: 0.1119 - loss: 4.1195 - val_accuracy: 0.1199 - val_loss: 4.6609\nEpoch 19/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.1237 - loss: 3.9421\nEpoch 19: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 426ms/step - accuracy: 0.1238 - loss: 3.9422 - val_accuracy: 0.1311 - val_loss: 4.5452\nEpoch 20/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.1361 - loss: 3.7935\nEpoch 20: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 411ms/step - accuracy: 0.1361 - loss: 3.7934 - val_accuracy: 0.1407 - val_loss: 4.4106\nEpoch 21/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389ms/step - accuracy: 0.1466 - loss: 3.6759\nEpoch 21: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.1466 - loss: 3.6751 - val_accuracy: 0.1492 - val_loss: 4.2931\nEpoch 22/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.1526 - loss: 3.5287\nEpoch 22: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 412ms/step - accuracy: 0.1526 - loss: 3.5280 - val_accuracy: 0.1602 - val_loss: 4.1776\nEpoch 23/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.1612 - loss: 3.3642\nEpoch 23: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 405ms/step - accuracy: 0.1612 - loss: 3.3641 - val_accuracy: 0.1627 - val_loss: 4.0676\nEpoch 24/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.1717 - loss: 3.2306\nEpoch 24: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 415ms/step - accuracy: 0.1717 - loss: 3.2306 - val_accuracy: 0.1696 - val_loss: 3.9663\nEpoch 25/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.1742 - loss: 3.1016\nEpoch 25: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 403ms/step - accuracy: 0.1743 - loss: 3.1018 - val_accuracy: 0.1758 - val_loss: 3.8781\nEpoch 26/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.1833 - loss: 2.9781\nEpoch 26: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 416ms/step - accuracy: 0.1832 - loss: 2.9786 - val_accuracy: 0.1813 - val_loss: 3.7859\nEpoch 27/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374ms/step - accuracy: 0.1900 - loss: 2.8732\nEpoch 27: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 409ms/step - accuracy: 0.1899 - loss: 2.8737 - val_accuracy: 0.1835 - val_loss: 3.7105\nEpoch 28/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375ms/step - accuracy: 0.1922 - loss: 2.8061\nEpoch 28: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 406ms/step - accuracy: 0.1922 - loss: 2.8059 - val_accuracy: 0.1852 - val_loss: 3.6406\nEpoch 29/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.1972 - loss: 2.7074\nEpoch 29: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 414ms/step - accuracy: 0.1972 - loss: 2.7075 - val_accuracy: 0.1918 - val_loss: 3.5706\nEpoch 30/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.1956 - loss: 2.6452\nEpoch 30: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 403ms/step - accuracy: 0.1957 - loss: 2.6449 - val_accuracy: 0.1938 - val_loss: 3.5086\nEpoch 31/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.2038 - loss: 2.5340\nEpoch 31: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 415ms/step - accuracy: 0.2038 - loss: 2.5343 - val_accuracy: 0.1963 - val_loss: 3.4424\nEpoch 32/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - accuracy: 0.2058 - loss: 2.4437\nEpoch 32: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 403ms/step - accuracy: 0.2058 - loss: 2.4444 - val_accuracy: 0.1999 - val_loss: 3.3901\nEpoch 33/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.2087 - loss: 2.4153\nEpoch 33: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 419ms/step - accuracy: 0.2088 - loss: 2.4151 - val_accuracy: 0.2035 - val_loss: 3.3429\nEpoch 34/50\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.2143 - loss: 2.3214\nEpoch 34: saving model to /kaggle/working/model_checkpoint.keras\n\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 416ms/step - accuracy: 0.2143 - loss: 2.3217 - val_accuracy: 0.2049 - val_loss: 3.2945\nEpoch 35/50\n\u001b[1m16/47\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 376ms/step - accuracy: 0.2103 - loss: 2.2751",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# # Loads the weights\n",
        "model.load_weights('/kaggle/working/cp.ckpt')"
      ],
      "metadata": {
        "trusted": true,
        "id": "qSjEqePiMiBL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = Input(shape = (output_sequence.shape[1],))\n",
        "decoder_embedding_layer = Embedding(input_dim = len(total_output_words)+1,output_dim = 100,mask_zero = True)(decoder_inputs)\n",
        "\n",
        "decoder_state_input_h = Input(shape=(lstm_units,))\n",
        "decoder_state_input_c = Input(shape=(lstm_units,))\n",
        "\n",
        "decoder_input_state = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "decoder = LSTM(lstm_units,return_sequences = True,return_state = True)\n",
        "decoder_outputs,state_h,state_c = decoder(decoder_embedding_layer,initial_state=decoder_input_state)\n",
        "\n",
        "decoder_output_state = [state_h,state_c ]\n",
        "\n",
        "decoder_dense = Dense(len(total_output_words)+1,activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = Model([decoder_inputs]+decoder_input_state,[decoder_outputs]+decoder_output_state)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5QTAm2FPMiBM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_seq(input_seq):\n",
        "\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    print(type(states_value))\n",
        "\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0,0] = output_tokenizer.word_index['<start>']\n",
        "\n",
        "    decode_senetence = ''\n",
        "\n",
        "    stop_condition = False\n",
        "\n",
        "    while not stop_condition:\n",
        "\n",
        "        output_tokens,h,c = decoder_model.predict([target_seq]+states_value)\n",
        "\n",
        "                                #(batch_size, sequence_length, vocab_size)\n",
        "        sampled_token_index = np.argmax(output_tokens[0,-1,:])\n",
        "        sampled_word = reverse_output_word_index(sampled_token_index)\n",
        "\n",
        "        decoded_sentence+= ''+=sampled_word\n",
        "\n",
        "        if (sampled_word=='<end>' or len(decoded_sentence) > max_output_length):\n",
        "            stop_condition = True\n",
        "\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0,0] = sampled_token_index\n",
        "\n",
        "        states_value = [h,c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "reverse_output_word_index = {index:word for word,index in output_tokenizer.word_index.items()}\n",
        "max_output_length = decoder_input_data.shape[1]\n",
        "\n",
        "input_sentence = \"hello how are you\"\n",
        "input_seq = input_tokenizer.texts_to_sequences([input_sentence])\n",
        "input_seq = tf.keras.preprocessing.sequence.pad_sequences(input_seq, maxlen=max_input_length, padding='post')\n",
        "\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print(\"Predicted Output:\", decoded_sentence)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y6VATGFZMiBN"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}